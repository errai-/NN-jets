{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demonstrera",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/errai-/NN-test/blob/master/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVOfyW__KqTM",
        "colab_type": "text"
      },
      "source": [
        "# Using tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2r9hlDj8bZe",
        "colab_type": "code",
        "outputId": "def2a584-b6c0-4d76-fc36-008c5b81a3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/amld_data/datasetto_cjet'\n",
        "\n",
        "# In Jupyter, you would need to install TF 2.0 via !pip.\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import base64, collections, io, itertools, functools, json, os, random, re, textwrap, time, urllib, xml\n",
        "\n",
        "# Tested with TensorFlow 2.1.0\n",
        "print('version={}, CUDA={}, GPU={}, TPU={}'.format(\n",
        "    tf.__version__, tf.test.is_built_with_cuda(),\n",
        "    # GPU attached?\n",
        "    len(tf.config.list_physical_devices('GPU')) > 0,\n",
        "    # TPU accessible? (only works on Colab)\n",
        "    'COLAB_TPU_ADDR' in os.environ))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython import display\n",
        "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import altair as alt\n",
        "\n",
        "pttrans = FunctionTransformer(lambda x : (x-15)/485.0)\n",
        "ptinv = FunctionTransformer(lambda x : x*485+15)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "version=2.2.0, CUDA=True, GPU=False, TPU=False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84VpX-kTKNBG",
        "colab_type": "code",
        "outputId": "2e36d326-a5d5-44cb-b7a8-ce2967080bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "if data_path.startswith('/content/gdrive/'):\n",
        "  from google.colab import drive\n",
        "  assert data_path.startswith('/content/gdrive/My Drive/'), 'Google Drive paths must start with \"/content/gdrive/My Drive/\"!'\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "if data_path.startswith('gs://'):\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK2fsbTpOKHz",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title `make_sharded_files()` code\n",
        "#@markdown Helper code to create sharded recordio files.\n",
        "#@markdown Simply **click \"execute\"** and continue to the next cell.\n",
        "#@markdown No need to read through this code to understand the remainder of the Colab.\n",
        "#@markdown \n",
        "#@markdown If you want to have a look anyways, you can double-click this cell or click on the three dots\n",
        "#@markdown and then select \"Form\" and then \"Show Code\" (shortcut `<Ctrl-M> <F>`).\n",
        "\n",
        "# Helper code to create sharded recordio files.\n",
        "# (No need to read through this.)\n",
        "\n",
        "def get_split(i, splits):\n",
        "  \"\"\"Returns key from \"splits\" for iteration \"i\".\"\"\"\n",
        "  i %= sum(splits.values())\n",
        "  for split in sorted(splits):\n",
        "    if i < splits[split]:\n",
        "      return split\n",
        "    i -= splits[split]\n",
        "\n",
        "def example_to_dict(example):\n",
        "  \"\"\"Converts a tf.train.Example to a dictionary.\"\"\"\n",
        "  example_dict = {}\n",
        "  for name, value in example.features.feature.items():\n",
        "    if value.HasField('bytes_list'):\n",
        "      value = value.bytes_list.value\n",
        "    elif value.HasField('int64_list'):\n",
        "      value = value.int64_list.value\n",
        "    elif value.HasField('float_list'):\n",
        "      value = value.float_list.value\n",
        "    else:\n",
        "      raise 'Unknown *_list type!'\n",
        "    if len(value) == 1:\n",
        "      example_dict[name] = value[0]\n",
        "    else:\n",
        "      example_dict[name] = np.array(value)\n",
        "  return example_dict\n",
        "\n",
        "pi = np.pi\n",
        "\n",
        "def phinorm(phi):\n",
        "  while phi<-pi:\n",
        "    phi += 2*pi\n",
        "  while phi>pi:\n",
        "    phi -= 2*pi\n",
        "  return phi/pi\n",
        "\n",
        "def make_sharded_files(make_example, path, counts, splits, shards=10, overwrite=False, report_dt=10, make_df=False):\n",
        "\n",
        "  # Prepare output.\n",
        "  if not tf.io.gfile.exists(path):\n",
        "    tf.io.gfile.makedirs(path)\n",
        "  paths = {\n",
        "      split: ['%s/%s-%05d-of-%05d' % (path, split, i, shards)\n",
        "              for i in range(shards)]\n",
        "      for split in splits\n",
        "  }\n",
        "  assert overwrite or not tf.io.gfile.exists(paths.values()[0][0])\n",
        "  writers = {\n",
        "      split: [tf.io.TFRecordWriter(ps[i]) for i in range(shards)]\n",
        "      for split, ps in paths.items()\n",
        "  }\n",
        "  t0 = time.time()\n",
        "  examples_per_split = collections.defaultdict(int)\n",
        "  i, n = 0, counts\n",
        "  rows = []\n",
        "  phis0=[pi/6.0,-pi/5.0,(3.0/5)*pi,(-4.0/5)*pi,pi/4.0,-pi/3.0]\n",
        "\n",
        "  # Create examples.\n",
        "  while i<n:\n",
        "    split = get_split(i, splits)\n",
        "    writer = writers[split][examples_per_split[split] % shards]\n",
        "\n",
        "    x = 1.0\n",
        "    phishift = 2*pi*random.random()\n",
        "    photpt = 30+270*random.random()\n",
        "    pts,projs,phis=[],[],[]\n",
        "    for j in range(len(phis0)):\n",
        "      phi = phis0[j]+0.2*random.random()\n",
        "      nxt = random.random()\n",
        "      nxt = max(nxt,1-nxt)\n",
        "      nxt *= x\n",
        "      nxt *= (-1 if abs(phi)>pi/2.0 else 1)\n",
        "      x -= nxt\n",
        "      pt = photpt*nxt/np.cos(phi)\n",
        "      scale = max(0.5,random.gauss(1 - np.exp(-0.05*pt),0.1*np.exp(-0.01*pt)))\n",
        "      projs.append(scale*nxt)\n",
        "      pts.append(pttrans.transform(scale*pt))\n",
        "      phis.append(phinorm(phi+phishift))\n",
        "  \n",
        "    example = make_example(projs,pts,phis)\n",
        "    writer.write(example.SerializeToString())\n",
        "    if make_df:\n",
        "      example.features.feature['split'].bytes_list.value.append(split.encode('utf8'))\n",
        "      rows.append(example_to_dict(example))\n",
        "    examples_per_split[split] += 1\n",
        "    i += 1\n",
        "    if report_dt > 0 and time.time() - t0 > report_dt:\n",
        "      print('processed %d/%d (%.2f%%)' % (i, n, 100. * i / n))\n",
        "      t0 = time.time()\n",
        "  # Store results.\n",
        "  for split in splits:\n",
        "    for writer in writers[split]:\n",
        "      writer.close()\n",
        "  with tf.io.gfile.GFile('%s/counts.json' % path, 'w') as f:\n",
        "    json.dump(examples_per_split, f)\n",
        "  if make_df:\n",
        "    df_path = '%s/dataframe.pkl' % path\n",
        "    print('Writing %s...' % df_path)\n",
        "    pd.DataFrame(rows).to_pickle(df_path)\n",
        "  return dict(**examples_per_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYTCanh8Pz1R",
        "colab_type": "code",
        "outputId": "a1a51a29-b02f-4a00-bb96-5b6159e8da68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "def make_example_jetdata(projs, pts, phis):\n",
        "  \"\"\"Converts QuickDraw dictionary to example with rasterized data.\n",
        "  \n",
        "  Args:\n",
        "\n",
        "  Returns:\n",
        "    A tf.train.Example protocol buffer (with 'label', 'img_64', and additional\n",
        "    metadata features).\n",
        "  \"\"\"\n",
        "  example = tf.train.Example()\n",
        "  example.features.feature['projs'].float_list.value.extend(np.asarray(projs))\n",
        "  example.features.feature['pts'].float_list.value.extend(np.asarray(pts))\n",
        "  example.features.feature['phis'].float_list.value.extend(np.asarray(phis))\n",
        "\n",
        "  return example\n",
        "\n",
        "# Create the (jet) dataset.\n",
        "t0 = time.time()\n",
        "examples_per_split = make_sharded_files(\n",
        "    make_example=make_example_jetdata,\n",
        "    path=data_path,\n",
        "    # Creating 50k train, 20k eval and 10k test examples.\n",
        "    counts=80000,\n",
        "    shards=2,\n",
        "    splits=dict(train=5, eval=2, test=1),\n",
        "    overwrite=True,\n",
        "    # Note: Set this to False when generating large datasets.\n",
        "    make_df=True,\n",
        ")\n",
        "\n",
        "print('stored data to \"%s\"' % data_path)\n",
        "print('generated %s examples in %d seconds' % (examples_per_split, time.time() - t0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 47044/80000 (58.80%)\n",
            "Writing /content/gdrive/My Drive/amld_data/datasetto_cjet/dataframe.pkl...\n",
            "stored data to \"/content/gdrive/My Drive/amld_data/datasetto_cjet\"\n",
            "generated {'eval': 20000, 'test': 10000, 'train': 50000} examples in 18 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAz1wTwOLX4j",
        "colab_type": "text"
      },
      "source": [
        "## Data from Protobufs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9izb-IbIAhZ",
        "colab_type": "code",
        "outputId": "11d606fd-98e5-4cc9-ae82-b1bbbf0bbb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "counts = json.load(tf.io.gfile.GFile('{}/counts.json'.format(data_path)))\n",
        "print('Splits sizes:', counts)\n",
        "\n",
        "feature_spec = {\n",
        "    'projs': tf.io.FixedLenFeature(shape=[6], dtype=float),\n",
        "    'pts': tf.io.FixedLenFeature(shape=[6], dtype=float),\n",
        "    'phis': tf.io.FixedLenFeature(shape=[6], dtype=float),\n",
        "}\n",
        "\n",
        "def parse_example(serialized_example):\n",
        "  features = tf.io.parse_single_example(serialized_example, feature_spec)\n",
        "  return {\"j1\" : tf.stack([features['pts'][0],features['phis'][0]]),\"p1\" : features['projs'][0],\n",
        "          \"j2\" : tf.stack([features['pts'][1],features['phis'][1]]),\"p2\" : features['projs'][1],\n",
        "          \"j3\" : tf.stack([features['pts'][2],features['phis'][2]]),\"p3\" : features['projs'][2],\n",
        "          \"j4\" : tf.stack([features['pts'][3],features['phis'][3]]),\"p4\" : features['projs'][3],\n",
        "          \"j5\" : tf.stack([features['pts'][4],features['phis'][4]]),\"p5\" : features['projs'][4],\n",
        "          \"j6\" : tf.stack([features['pts'][5],features['phis'][5]]),\"p6\" : features['projs'][5]},{\"target\" : tf.constant(1.0,float,shape=(1,))}\n",
        "\n",
        "batch_size = 20\n",
        "steps_per_epoch = counts['train'] // batch_size\n",
        "eval_steps_per_epoch = counts['eval'] // batch_size\n",
        "\n",
        "# Create datasets from TFRecord files.\n",
        "train_ds = tf.data.TFRecordDataset(tf.io.gfile.glob('{}/train-*'.format(data_path)))\n",
        "train_ds = train_ds.map(parse_example)\n",
        "train_ds = train_ds.batch(batch_size).repeat()\n",
        "\n",
        "eval_ds = tf.data.TFRecordDataset(tf.io.gfile.glob('{}/eval-*'.format(data_path)))\n",
        "eval_ds = eval_ds.map(parse_example)\n",
        "eval_ds = eval_ds.batch(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splits sizes: {'eval': 20000, 'test': 10000, 'train': 50000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28qPSmJMaxBh",
        "colab_type": "code",
        "outputId": "f1571237-f02c-4fb1-d538-9614494aaaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "in1 = tf.keras.Input(shape=(2,), name=\"j1\")\n",
        "in2 = tf.keras.Input(shape=(2,), name=\"j2\")\n",
        "in3 = tf.keras.Input(shape=(2,), name=\"j3\")\n",
        "in4 = tf.keras.Input(shape=(2,), name=\"j4\")\n",
        "in5 = tf.keras.Input(shape=(2,), name=\"j5\")\n",
        "in6 = tf.keras.Input(shape=(2,), name=\"j6\")\n",
        "p1 = tf.keras.Input(shape=(1,), name=\"p1\")\n",
        "p2 = tf.keras.Input(shape=(1,), name=\"p2\")\n",
        "p3 = tf.keras.Input(shape=(1,), name=\"p3\")\n",
        "p4 = tf.keras.Input(shape=(1,), name=\"p4\")\n",
        "p5 = tf.keras.Input(shape=(1,), name=\"p5\")\n",
        "p6 = tf.keras.Input(shape=(1,), name=\"p6\")\n",
        "\n",
        "l1 = tf.keras.layers.Dense(40, activation='swish', kernel_initializer='he_uniform')\n",
        "l2 = tf.keras.layers.Dense(40, activation='swish', kernel_initializer='he_uniform')\n",
        "l3 = tf.keras.layers.Dense(40, activation='swish', kernel_initializer='he_uniform')\n",
        "l4 = tf.keras.layers.Dense(40, activation='tanh', kernel_initializer='he_uniform')\n",
        "lN = tf.keras.layers.Dense(1, activation='linear', kernel_initializer='he_uniform', name='corr')\n",
        "\n",
        "out1 = tf.keras.layers.Multiply()([p1,lN(l4(l3(l2(l1(in1)))))])\n",
        "out2 = tf.keras.layers.Multiply()([p2,lN(l4(l3(l2(l1(in2)))))])\n",
        "out3 = tf.keras.layers.Multiply()([p3,lN(l4(l3(l2(l1(in3)))))])\n",
        "out4 = tf.keras.layers.Multiply()([p4,lN(l4(l3(l2(l1(in4)))))])\n",
        "out5 = tf.keras.layers.Multiply()([p5,lN(l4(l3(l2(l1(in5)))))])\n",
        "out6 = tf.keras.layers.Multiply()([p6,lN(l4(l3(l2(l1(in6)))))])\n",
        "\n",
        "out = tf.keras.layers.Add(name='target')([out1,out2,out3,out4,out5,out6])\n",
        "\n",
        "moderu = tf.keras.Model([in1,p1,in2,p2,in3,p3,in4,p4,in5,p5,in6,p6],out,name=\"jets\")\n",
        "\n",
        "moderu.compile(optimizer='sgd', loss='mae',  metrics=['mse','mae'])\n",
        "#moderu.summary()\n",
        "\n",
        "moderu.fit(train_ds, steps_per_epoch=steps_per_epoch, epochs=750, verbose=True)\n",
        "\n",
        "inn = tf.keras.Input(shape=(2,), name=\"j\")\n",
        "onn = lN(l4(l3(l2(l1(inn)))))\n",
        "simpuru = tf.keras.Model(inn,onn,name=\"jets\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0527 - mse: 0.0075 - mae: 0.0527\n",
            "Epoch 2/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0441 - mse: 0.0041 - mae: 0.0441\n",
            "Epoch 3/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0427 - mse: 0.0039 - mae: 0.0427\n",
            "Epoch 4/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0416 - mse: 0.0037 - mae: 0.0416\n",
            "Epoch 5/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0407 - mse: 0.0036 - mae: 0.0407\n",
            "Epoch 6/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0397 - mse: 0.0034 - mae: 0.0397\n",
            "Epoch 7/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0388 - mse: 0.0032 - mae: 0.0388\n",
            "Epoch 8/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0380 - mse: 0.0030 - mae: 0.0380\n",
            "Epoch 9/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0373 - mse: 0.0028 - mae: 0.0373\n",
            "Epoch 10/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0369 - mse: 0.0027 - mae: 0.0369\n",
            "Epoch 11/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0364 - mse: 0.0026 - mae: 0.0364\n",
            "Epoch 12/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0360 - mse: 0.0025 - mae: 0.0360\n",
            "Epoch 13/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0354 - mse: 0.0024 - mae: 0.0354\n",
            "Epoch 14/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0348 - mse: 0.0023 - mae: 0.0348\n",
            "Epoch 15/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0343 - mse: 0.0022 - mae: 0.0343\n",
            "Epoch 16/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0338 - mse: 0.0022 - mae: 0.0338\n",
            "Epoch 17/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0333 - mse: 0.0021 - mae: 0.0333\n",
            "Epoch 18/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0328 - mse: 0.0020 - mae: 0.0328\n",
            "Epoch 19/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0325 - mse: 0.0020 - mae: 0.0325\n",
            "Epoch 20/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0320 - mse: 0.0019 - mae: 0.0320\n",
            "Epoch 21/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0318 - mse: 0.0019 - mae: 0.0318\n",
            "Epoch 22/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0315 - mse: 0.0018 - mae: 0.0315\n",
            "Epoch 23/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0311 - mse: 0.0018 - mae: 0.0311\n",
            "Epoch 24/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0309 - mse: 0.0018 - mae: 0.0309\n",
            "Epoch 25/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0306 - mse: 0.0017 - mae: 0.0306\n",
            "Epoch 26/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0303 - mse: 0.0017 - mae: 0.0303\n",
            "Epoch 27/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0300 - mse: 0.0017 - mae: 0.0300\n",
            "Epoch 28/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0298 - mse: 0.0016 - mae: 0.0298\n",
            "Epoch 29/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0296 - mse: 0.0016 - mae: 0.0296\n",
            "Epoch 30/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0293 - mse: 0.0016 - mae: 0.0293\n",
            "Epoch 31/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0291 - mse: 0.0016 - mae: 0.0291\n",
            "Epoch 32/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0289 - mse: 0.0015 - mae: 0.0289\n",
            "Epoch 33/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0288 - mse: 0.0015 - mae: 0.0288\n",
            "Epoch 34/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0287 - mse: 0.0015 - mae: 0.0287\n",
            "Epoch 35/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0285 - mse: 0.0015 - mae: 0.0285\n",
            "Epoch 36/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0284 - mse: 0.0015 - mae: 0.0284\n",
            "Epoch 37/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0283 - mse: 0.0015 - mae: 0.0283\n",
            "Epoch 38/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0282 - mse: 0.0015 - mae: 0.0282\n",
            "Epoch 39/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0281 - mse: 0.0015 - mae: 0.0281\n",
            "Epoch 40/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0280 - mse: 0.0014 - mae: 0.0280\n",
            "Epoch 41/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0279 - mse: 0.0014 - mae: 0.0279\n",
            "Epoch 42/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0278 - mse: 0.0014 - mae: 0.0278\n",
            "Epoch 43/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0277 - mse: 0.0014 - mae: 0.0277\n",
            "Epoch 44/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0276 - mse: 0.0014 - mae: 0.0276\n",
            "Epoch 45/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0275 - mse: 0.0014 - mae: 0.0275\n",
            "Epoch 46/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0274 - mse: 0.0014 - mae: 0.0274\n",
            "Epoch 47/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0274 - mse: 0.0014 - mae: 0.0274\n",
            "Epoch 48/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0273 - mse: 0.0014 - mae: 0.0273\n",
            "Epoch 49/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0273 - mse: 0.0014 - mae: 0.0273\n",
            "Epoch 50/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0272 - mse: 0.0014 - mae: 0.0272\n",
            "Epoch 51/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0271 - mse: 0.0014 - mae: 0.0271\n",
            "Epoch 52/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0271 - mse: 0.0014 - mae: 0.0271\n",
            "Epoch 53/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0271 - mse: 0.0014 - mae: 0.0271\n",
            "Epoch 54/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0270 - mse: 0.0014 - mae: 0.0270\n",
            "Epoch 55/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0270 - mse: 0.0013 - mae: 0.0270\n",
            "Epoch 56/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0269 - mse: 0.0013 - mae: 0.0269\n",
            "Epoch 57/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0269 - mse: 0.0013 - mae: 0.0269\n",
            "Epoch 58/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0268 - mse: 0.0013 - mae: 0.0268\n",
            "Epoch 59/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0268 - mse: 0.0013 - mae: 0.0268\n",
            "Epoch 60/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267\n",
            "Epoch 61/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267\n",
            "Epoch 62/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267\n",
            "Epoch 63/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0266 - mse: 0.0013 - mae: 0.0266\n",
            "Epoch 64/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267\n",
            "Epoch 65/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0267 - mse: 0.0013 - mae: 0.0267\n",
            "Epoch 66/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0266 - mse: 0.0013 - mae: 0.0266\n",
            "Epoch 67/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0265 - mse: 0.0013 - mae: 0.0265\n",
            "Epoch 68/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0266 - mse: 0.0013 - mae: 0.0266\n",
            "Epoch 69/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0265 - mse: 0.0013 - mae: 0.0265\n",
            "Epoch 70/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0265 - mse: 0.0013 - mae: 0.0265\n",
            "Epoch 71/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0265 - mse: 0.0013 - mae: 0.0265\n",
            "Epoch 72/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0264 - mse: 0.0013 - mae: 0.0264\n",
            "Epoch 73/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0265 - mse: 0.0013 - mae: 0.0265\n",
            "Epoch 74/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0264 - mse: 0.0013 - mae: 0.0264\n",
            "Epoch 75/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0264 - mse: 0.0013 - mae: 0.0264\n",
            "Epoch 76/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0264 - mse: 0.0013 - mae: 0.0264\n",
            "Epoch 77/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 78/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 79/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 80/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 81/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 82/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 83/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 84/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0263 - mse: 0.0013 - mae: 0.0263\n",
            "Epoch 85/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 86/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 87/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 88/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 89/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0262 - mse: 0.0013 - mae: 0.0262\n",
            "Epoch 90/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 91/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 92/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 93/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 94/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 95/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 96/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 97/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 98/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0261 - mse: 0.0013 - mae: 0.0261\n",
            "Epoch 99/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 100/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 101/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 102/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 103/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 104/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 105/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 106/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 107/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 108/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0260 - mse: 0.0013 - mae: 0.0260\n",
            "Epoch 109/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 110/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 111/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 112/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 113/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 114/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 115/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 116/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 117/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 118/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 119/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0259 - mse: 0.0013 - mae: 0.0259\n",
            "Epoch 120/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 121/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 122/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 123/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 124/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 125/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 126/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 127/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 128/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 129/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 130/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 131/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 132/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 133/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 134/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 135/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 136/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 137/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 138/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0258 - mse: 0.0013 - mae: 0.0258\n",
            "Epoch 139/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 140/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 141/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 142/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 143/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 144/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 145/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 146/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 147/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 148/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 149/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 150/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 151/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 152/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 153/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 154/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0257 - mse: 0.0013 - mae: 0.0257\n",
            "Epoch 155/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 156/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 157/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 158/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 159/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 160/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 161/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 162/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 163/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 164/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 165/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0013 - mae: 0.0256\n",
            "Epoch 166/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 167/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 168/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 169/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 170/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 171/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 172/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 173/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 174/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 175/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 176/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 177/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 178/750\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 179/750\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 180/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0256 - mse: 0.0012 - mae: 0.0256\n",
            "Epoch 181/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 182/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 183/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 184/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 185/750\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 186/750\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 187/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 188/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 189/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 190/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 191/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 192/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 193/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 194/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 195/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 196/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 197/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 198/750\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 199/750\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 200/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 201/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 202/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 203/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 204/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 205/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 206/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 207/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 208/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 209/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 210/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 211/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 212/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 213/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 214/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 215/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 216/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 217/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 218/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 219/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 220/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 221/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 222/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 223/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 224/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 225/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 226/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 227/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 228/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 229/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 230/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 231/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 232/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 233/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 234/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 235/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 236/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 237/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 238/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 239/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 240/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 241/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 242/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 243/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 244/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 245/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 246/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 247/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 248/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 249/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 250/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 251/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 252/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 253/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 254/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 255/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 256/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 257/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 258/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 259/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 260/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 261/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 262/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 263/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 264/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 265/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 266/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 267/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0255 - mse: 0.0012 - mae: 0.0255\n",
            "Epoch 268/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 269/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 270/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 271/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 272/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 273/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 274/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 275/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 276/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 277/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 278/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 279/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 280/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 281/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 282/750\n",
            "2500/2500 [==============================] - 11s 4ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 283/750\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 284/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 285/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 286/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 287/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 288/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 289/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 290/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 291/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 292/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 293/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 294/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 295/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 296/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 297/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 298/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 299/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 300/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 301/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 302/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 303/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 304/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 305/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 306/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 307/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 308/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 309/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 310/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 311/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 312/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 313/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 314/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 315/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 316/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 317/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 318/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 319/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 320/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 321/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 322/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 323/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 324/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 325/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 326/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 327/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 328/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 329/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 330/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 331/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 332/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 333/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 334/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 335/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 336/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 337/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 338/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 339/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 340/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 341/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 342/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 343/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 344/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 345/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 346/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 347/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 348/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 349/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 350/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 351/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 352/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 353/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 354/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 355/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 356/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 357/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 358/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 359/750\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 360/750\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 361/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 362/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 363/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 364/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 365/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 366/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 367/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 368/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 369/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 370/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 371/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 372/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 373/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 374/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 375/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 376/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 377/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 378/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 379/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 380/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 381/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 382/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 383/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 384/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 385/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 386/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 387/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 388/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 389/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 390/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 391/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 392/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 393/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 394/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 395/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 396/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 397/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 398/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 399/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 400/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 401/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 402/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 403/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 404/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 405/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 406/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 407/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 408/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 409/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 410/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 411/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 412/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 413/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 414/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 415/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 416/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 417/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 418/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 419/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 420/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 421/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 422/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 423/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 424/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 425/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 426/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 427/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 428/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 429/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 430/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 431/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 432/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 433/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 434/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 435/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 436/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 437/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 438/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 439/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 440/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 441/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 442/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 443/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 444/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 445/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 446/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 447/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 448/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 449/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 450/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 451/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 452/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 453/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 454/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 455/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 456/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 457/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 458/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 459/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 460/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 461/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 462/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 463/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 464/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 465/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 466/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 467/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 468/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 469/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 470/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 471/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 472/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 473/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 474/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0254 - mse: 0.0012 - mae: 0.0254\n",
            "Epoch 475/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 476/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 477/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 478/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 479/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 480/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 481/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 482/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 483/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 484/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 485/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 486/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 487/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 488/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 489/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 490/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 491/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 492/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 493/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 494/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 495/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 496/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 497/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 498/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 499/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 500/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 501/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 502/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 503/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 504/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 505/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 506/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 507/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 508/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 509/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 510/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 511/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 512/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 513/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 514/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 515/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 516/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 517/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 518/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 519/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 520/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 521/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 522/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 523/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 524/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 525/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 526/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 527/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 528/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 529/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 530/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 531/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 532/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 533/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 534/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 535/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 536/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 537/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 538/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 539/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 540/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 541/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 542/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 543/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 544/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 545/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 546/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 547/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 548/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 549/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 550/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 551/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 552/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 553/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 554/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 555/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 556/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 557/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 558/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 559/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 560/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 561/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 562/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 563/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 564/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 565/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 566/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 567/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 568/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 569/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 570/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 571/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 572/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 573/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 574/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 575/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 576/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 577/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 578/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 579/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 580/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 581/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 582/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 583/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 584/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 585/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 586/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0253 - mse: 0.0012 - mae: 0.0253\n",
            "Epoch 587/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 588/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 589/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 590/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 591/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 592/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 593/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 594/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 595/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 596/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 597/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 598/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 599/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 600/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 601/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 602/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 603/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 604/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 605/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 606/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 607/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 608/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 609/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 610/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 611/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 612/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 613/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 614/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 615/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 616/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 617/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 618/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 619/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 620/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 621/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 622/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 623/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 624/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 625/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 626/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 627/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 628/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 629/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 630/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 631/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 632/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 633/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 634/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 635/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 636/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 637/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 638/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 639/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 640/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 641/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 642/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 643/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 644/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 645/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 646/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 647/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 648/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 649/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 650/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 651/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 652/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 653/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 654/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0252 - mse: 0.0012 - mae: 0.0252\n",
            "Epoch 655/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 656/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 657/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 658/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 659/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 660/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 661/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 662/750\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 663/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 664/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 665/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 666/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 667/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 668/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 669/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 670/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 671/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 672/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 673/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 674/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 675/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 676/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 677/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 678/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 679/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 680/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 681/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 682/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 683/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 684/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 685/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 686/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 687/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 688/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 689/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 690/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 691/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 692/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 693/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 694/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 695/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 696/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 697/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 698/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 699/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 700/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 701/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 702/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 703/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 704/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 705/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 706/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 707/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 708/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 709/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 710/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 711/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 712/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 713/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 714/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0251 - mse: 0.0012 - mae: 0.0251\n",
            "Epoch 715/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 716/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 717/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 718/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 719/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 720/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 721/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 722/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 723/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 724/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 725/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 726/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 727/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 728/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 729/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 730/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 731/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 732/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 733/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 734/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 735/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 736/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 737/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 738/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 739/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 740/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 741/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 742/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 743/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 744/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 745/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 746/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 747/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 748/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 749/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n",
            "Epoch 750/750\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 0.0250 - mse: 0.0012 - mae: 0.0250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhx3y8FDJ7-R",
        "colab_type": "code",
        "outputId": "eb402ded-ddcb-4d2b-d18d-67a1831de358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "def coeffrecurse(pt,lvl=0):\n",
        "  if lvl>0:\n",
        "    return 1.0/(1-np.exp(-0.05*pt*coeffrecurse(pt,lvl-1)))\n",
        "  else:\n",
        "    return 1.0\n",
        "\n",
        "pts = np.asarray([x for x in range(10,500,5)], dtype=float)\n",
        "ptst = pttrans.transform(pts)\n",
        "NRep = pts.shape[0]\n",
        "predm10 = simpuru.predict(tf.stack([ptst,NRep*[-1.0]],1))\n",
        "predm05 = simpuru.predict(tf.stack([ptst,NRep*[-0.5]],1))\n",
        "predpm0 = simpuru.predict(tf.stack([ptst,NRep*[ 0.0]],1))\n",
        "predp05 = simpuru.predict(tf.stack([ptst,NRep*[ 0.5]],1))\n",
        "predp10 = simpuru.predict(tf.stack([ptst,NRep*[ 1.0]],1))\n",
        "\n",
        "comp = np.asarray([coeffrecurse(x,10) for x in range(10,500,5)], dtype=float)\n",
        "\n",
        "plt.scatter(pts,predpm0)\n",
        "plt.scatter(pts,comp)\n",
        "plt.ylim(.95, 1.1)\n",
        "\n",
        "# make predictions for the input data\n",
        "x_plot = pts\n",
        "y_plot = comp\n",
        "yhat_plot = predpm0\n",
        "# report model error\n",
        "print('MSE: %.10f' % mean_squared_error(y_plot, yhat_plot))\n",
        "\n",
        "sdata = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                      'corr': y_plot.tolist(),\n",
        "                      'type': len(x_plot.tolist())*[\"Correct\"]})\n",
        "tdatapm0 = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                         'corr': predm05.tolist(),\n",
        "                         'type': len(x_plot.tolist())*[\"Prediction 0\"]})\n",
        "tdatam05 = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                         'corr': predm10.tolist(),\n",
        "                         'type': len(x_plot.tolist())*[\"Prediction -pi/2\"]})\n",
        "tdatam10 = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                         'corr': predpm0.tolist(),\n",
        "                         'type': len(x_plot.tolist())*[\"Prediction -pi\"]})\n",
        "tdatap05 = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                         'corr': predp05.tolist(),\n",
        "                         'type': len(x_plot.tolist())*[\"Prediction  pi/2\"]})\n",
        "tdatap10 = pd.DataFrame({'pt': x_plot.tolist(),\n",
        "                         'corr': predp10.tolist(),\n",
        "                         'type': len(x_plot.tolist())*[\"Prediction  pi\"]})\n",
        "alldata = pd.concat([sdata,tdatapm0,tdatam05,tdatap05,tdatam10,tdatap10])\n",
        "alt.Chart(alldata).mark_point().encode(\n",
        "    x=alt.X('pt:Q',scale=alt.Scale(domain=[20, 500])),\n",
        "    y=alt.Y('corr:Q',scale=alt.Scale(domain=[0.95, 1.4])),\n",
        "    color='type:N', \n",
        "    tooltip=['type','pt','corr']\n",
        "    ).properties(width=1500,height=500).interactive()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.0000467360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-b6cb603c7ce44ce9a69c327a47659a78\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-b6cb603c7ce44ce9a69c327a47659a78\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-b6cb603c7ce44ce9a69c327a47659a78\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-74bfc2ca02d8ad6b30af2becd84b1126\"}, \"mark\": \"point\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"type\"}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"type\"}, {\"type\": \"quantitative\", \"field\": \"pt\"}, {\"type\": \"nominal\", \"field\": \"corr\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"pt\", \"scale\": {\"domain\": [20, 500]}}, \"y\": {\"type\": \"quantitative\", \"field\": \"corr\", \"scale\": {\"domain\": [0.95, 1.4]}}}, \"height\": 500, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 1500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-74bfc2ca02d8ad6b30af2becd84b1126\": [{\"pt\": 10.0, \"corr\": 1.718858212227816, \"type\": \"Correct\"}, {\"pt\": 15.0, \"corr\": 1.4860645705458946, \"type\": \"Correct\"}, {\"pt\": 20.0, \"corr\": 1.3497377030416202, \"type\": \"Correct\"}, {\"pt\": 25.0, \"corr\": 1.2606984248962456, \"type\": \"Correct\"}, {\"pt\": 30.0, \"corr\": 1.1985425220093628, \"type\": \"Correct\"}, {\"pt\": 35.0, \"corr\": 1.1532595602163018, \"type\": \"Correct\"}, {\"pt\": 40.0, \"corr\": 1.119322668905769, \"type\": \"Correct\"}, {\"pt\": 45.0, \"corr\": 1.0934004592155453, \"type\": \"Correct\"}, {\"pt\": 50.0, \"corr\": 1.0733448866761386, \"type\": \"Correct\"}, {\"pt\": 55.0, \"corr\": 1.057695810229518, \"type\": \"Correct\"}, {\"pt\": 60.0, \"corr\": 1.0454183980775817, \"type\": \"Correct\"}, {\"pt\": 65.0, \"corr\": 1.0357547368217064, \"type\": \"Correct\"}, {\"pt\": 70.0, \"corr\": 1.028135391576668, \"type\": \"Correct\"}, {\"pt\": 75.0, \"corr\": 1.0221242105840858, \"type\": \"Correct\"}, {\"pt\": 80.0, \"corr\": 1.0173824088060561, \"type\": \"Correct\"}, {\"pt\": 85.0, \"corr\": 1.013644263511537, \"type\": \"Correct\"}, {\"pt\": 90.0, \"corr\": 1.0107000484448192, \"type\": \"Correct\"}, {\"pt\": 95.0, \"corr\": 1.0083836358853122, \"type\": \"Correct\"}, {\"pt\": 100.0, \"corr\": 1.0065632175612182, \"type\": \"Correct\"}, {\"pt\": 105.0, \"corr\": 1.0051341887264242, \"type\": \"Correct\"}, {\"pt\": 110.0, \"corr\": 1.0040135899541138, \"type\": \"Correct\"}, {\"pt\": 115.0, \"corr\": 1.0031357103913814, \"type\": \"Correct\"}, {\"pt\": 120.0, \"corr\": 1.0024485827126202, \"type\": \"Correct\"}, {\"pt\": 125.0, \"corr\": 1.0019111779330816, \"type\": \"Correct\"}, {\"pt\": 130.0, \"corr\": 1.0014911577041856, \"type\": \"Correct\"}, {\"pt\": 135.0, \"corr\": 1.0011630744939988, \"type\": \"Correct\"}, {\"pt\": 140.0, \"corr\": 1.000906932974259, \"type\": \"Correct\"}, {\"pt\": 145.0, \"corr\": 1.0007070428627067, \"type\": \"Correct\"}, {\"pt\": 150.0, \"corr\": 1.000551106576055, \"type\": \"Correct\"}, {\"pt\": 155.0, \"corr\": 1.00042949554585, \"type\": \"Correct\"}, {\"pt\": 160.0, \"corr\": 1.0003346776261772, \"type\": \"Correct\"}, {\"pt\": 165.0, \"corr\": 1.0002607650934714, \"type\": \"Correct\"}, {\"pt\": 170.0, \"corr\": 1.0002031585783036, \"type\": \"Correct\"}, {\"pt\": 175.0, \"corr\": 1.0001582670784006, \"type\": \"Correct\"}, {\"pt\": 180.0, \"corr\": 1.0001232881434314, \"type\": \"Correct\"}, {\"pt\": 185.0, \"corr\": 1.0000960355331732, \"type\": \"Correct\"}, {\"pt\": 190.0, \"corr\": 1.0000748042513077, \"type\": \"Correct\"}, {\"pt\": 195.0, \"corr\": 1.0000582649515186, \"type\": \"Correct\"}, {\"pt\": 200.0, \"corr\": 1.0000453813906944, \"type\": \"Correct\"}, {\"pt\": 205.0, \"corr\": 1.0000353459425841, \"type\": \"Correct\"}, {\"pt\": 210.0, \"corr\": 1.0000275292487322, \"type\": \"Correct\"}, {\"pt\": 215.0, \"corr\": 1.0000214409256385, \"type\": \"Correct\"}, {\"pt\": 220.0, \"corr\": 1.0000166989120185, \"type\": \"Correct\"}, {\"pt\": 225.0, \"corr\": 1.0000130055638043, \"type\": \"Correct\"}, {\"pt\": 230.0, \"corr\": 1.0000101290162726, \"type\": \"Correct\"}, {\"pt\": 235.0, \"corr\": 1.0000078886558166, \"type\": \"Correct\"}, {\"pt\": 240.0, \"corr\": 1.0000061437971304, \"type\": \"Correct\"}, {\"pt\": 245.0, \"corr\": 1.0000047848598177, \"type\": \"Correct\"}, {\"pt\": 250.0, \"corr\": 1.000003726493471, \"type\": \"Correct\"}, {\"pt\": 255.0, \"corr\": 1.000002902221438, \"type\": \"Correct\"}, {\"pt\": 260.0, \"corr\": 1.0000022602681002, \"type\": \"Correct\"}, {\"pt\": 265.0, \"corr\": 1.0000017603083529, \"type\": \"Correct\"}, {\"pt\": 270.0, \"corr\": 1.0000013709355928, \"type\": \"Correct\"}, {\"pt\": 275.0, \"corr\": 1.0000010676894755, \"type\": \"Correct\"}, {\"pt\": 280.0, \"corr\": 1.0000008315197304, \"type\": \"Correct\"}, {\"pt\": 285.0, \"corr\": 1.0000006475896608, \"type\": \"Correct\"}, {\"pt\": 290.0, \"corr\": 1.0000005043442286, \"type\": \"Correct\"}, {\"pt\": 295.0, \"corr\": 1.0000003927842331, \"type\": \"Correct\"}, {\"pt\": 300.0, \"corr\": 1.0000003059010103, \"type\": \"Correct\"}, {\"pt\": 305.0, \"corr\": 1.000000238236158, \"type\": \"Correct\"}, {\"pt\": 310.0, \"corr\": 1.0000001855386371, \"type\": \"Correct\"}, {\"pt\": 315.0, \"corr\": 1.0000001444977167, \"type\": \"Correct\"}, {\"pt\": 320.0, \"corr\": 1.0000001125349849, \"type\": \"Correct\"}, {\"pt\": 325.0, \"corr\": 1.0000000876423651, \"type\": \"Correct\"}, {\"pt\": 330.0, \"corr\": 1.0000000682559615, \"type\": \"Correct\"}, {\"pt\": 335.0, \"corr\": 1.000000053157808, \"type\": \"Correct\"}, {\"pt\": 340.0, \"corr\": 1.0000000413993497, \"type\": \"Correct\"}, {\"pt\": 345.0, \"corr\": 1.0000000322418505, \"type\": \"Correct\"}, {\"pt\": 350.0, \"corr\": 1.0000000251099812, \"type\": \"Correct\"}, {\"pt\": 355.0, \"corr\": 1.0000000195556746, \"type\": \"Correct\"}, {\"pt\": 360.0, \"corr\": 1.000000015229976, \"type\": \"Correct\"}, {\"pt\": 365.0, \"corr\": 1.0000000118611176, \"type\": \"Correct\"}, {\"pt\": 370.0, \"corr\": 1.0000000092374481, \"type\": \"Correct\"}, {\"pt\": 375.0, \"corr\": 1.0000000071941322, \"type\": \"Correct\"}, {\"pt\": 380.0, \"corr\": 1.000000005602796, \"type\": \"Correct\"}, {\"pt\": 385.0, \"corr\": 1.000000004363462, \"type\": \"Correct\"}, {\"pt\": 390.0, \"corr\": 1.0000000033982677, \"type\": \"Correct\"}, {\"pt\": 395.0, \"corr\": 1.0000000026465736, \"type\": \"Correct\"}, {\"pt\": 400.0, \"corr\": 1.0000000020611537, \"type\": \"Correct\"}, {\"pt\": 405.0, \"corr\": 1.000000001605228, \"type\": \"Correct\"}, {\"pt\": 410.0, \"corr\": 1.0000000012501529, \"type\": \"Correct\"}, {\"pt\": 415.0, \"corr\": 1.00000000097362, \"type\": \"Correct\"}, {\"pt\": 420.0, \"corr\": 1.0000000007582561, \"type\": \"Correct\"}, {\"pt\": 425.0, \"corr\": 1.0000000005905305, \"type\": \"Correct\"}, {\"pt\": 430.0, \"corr\": 1.0000000004599057, \"type\": \"Correct\"}, {\"pt\": 435.0, \"corr\": 1.0000000003581748, \"type\": \"Correct\"}, {\"pt\": 440.0, \"corr\": 1.0000000002789469, \"type\": \"Correct\"}, {\"pt\": 445.0, \"corr\": 1.000000000217244, \"type\": \"Correct\"}, {\"pt\": 450.0, \"corr\": 1.0000000001691898, \"type\": \"Correct\"}, {\"pt\": 455.0, \"corr\": 1.0000000001317653, \"type\": \"Correct\"}, {\"pt\": 460.0, \"corr\": 1.0000000001026188, \"type\": \"Correct\"}, {\"pt\": 465.0, \"corr\": 1.0000000000799196, \"type\": \"Correct\"}, {\"pt\": 470.0, \"corr\": 1.0000000000622415, \"type\": \"Correct\"}, {\"pt\": 475.0, \"corr\": 1.0000000000484737, \"type\": \"Correct\"}, {\"pt\": 480.0, \"corr\": 1.0000000000377514, \"type\": \"Correct\"}, {\"pt\": 485.0, \"corr\": 1.000000000029401, \"type\": \"Correct\"}, {\"pt\": 490.0, \"corr\": 1.0000000000228975, \"type\": \"Correct\"}, {\"pt\": 495.0, \"corr\": 1.0000000000178326, \"type\": \"Correct\"}, {\"pt\": 10.0, \"corr\": [1.762274980545044], \"type\": \"Prediction 0\"}, {\"pt\": 15.0, \"corr\": [1.5273630619049072], \"type\": \"Prediction 0\"}, {\"pt\": 20.0, \"corr\": [1.3704345226287842], \"type\": \"Prediction 0\"}, {\"pt\": 25.0, \"corr\": [1.272128939628601], \"type\": \"Prediction 0\"}, {\"pt\": 30.0, \"corr\": [1.2074834108352661], \"type\": \"Prediction 0\"}, {\"pt\": 35.0, \"corr\": [1.1624035835266113], \"type\": \"Prediction 0\"}, {\"pt\": 40.0, \"corr\": [1.1294087171554565], \"type\": \"Prediction 0\"}, {\"pt\": 45.0, \"corr\": [1.1043214797973633], \"type\": \"Prediction 0\"}, {\"pt\": 50.0, \"corr\": [1.0847004652023315], \"type\": \"Prediction 0\"}, {\"pt\": 55.0, \"corr\": [1.0690604448318481], \"type\": \"Prediction 0\"}, {\"pt\": 60.0, \"corr\": [1.0564534664154053], \"type\": \"Prediction 0\"}, {\"pt\": 65.0, \"corr\": [1.0462380647659302], \"type\": \"Prediction 0\"}, {\"pt\": 70.0, \"corr\": [1.0379526615142822], \"type\": \"Prediction 0\"}, {\"pt\": 75.0, \"corr\": [1.0312470197677612], \"type\": \"Prediction 0\"}, {\"pt\": 80.0, \"corr\": [1.0258430242538452], \"type\": \"Prediction 0\"}, {\"pt\": 85.0, \"corr\": [1.0215131044387817], \"type\": \"Prediction 0\"}, {\"pt\": 90.0, \"corr\": [1.01806640625], \"type\": \"Prediction 0\"}, {\"pt\": 95.0, \"corr\": [1.0153427124023438], \"type\": \"Prediction 0\"}, {\"pt\": 100.0, \"corr\": [1.0132060050964355], \"type\": \"Prediction 0\"}, {\"pt\": 105.0, \"corr\": [1.0115413665771484], \"type\": \"Prediction 0\"}, {\"pt\": 110.0, \"corr\": [1.0102524757385254], \"type\": \"Prediction 0\"}, {\"pt\": 115.0, \"corr\": [1.00925874710083], \"type\": \"Prediction 0\"}, {\"pt\": 120.0, \"corr\": [1.0084933042526245], \"type\": \"Prediction 0\"}, {\"pt\": 125.0, \"corr\": [1.0079015493392944], \"type\": \"Prediction 0\"}, {\"pt\": 130.0, \"corr\": [1.0074386596679688], \"type\": \"Prediction 0\"}, {\"pt\": 135.0, \"corr\": [1.0070695877075195], \"type\": \"Prediction 0\"}, {\"pt\": 140.0, \"corr\": [1.006765604019165], \"type\": \"Prediction 0\"}, {\"pt\": 145.0, \"corr\": [1.006504774093628], \"type\": \"Prediction 0\"}, {\"pt\": 150.0, \"corr\": [1.0062700510025024], \"type\": \"Prediction 0\"}, {\"pt\": 155.0, \"corr\": [1.006049394607544], \"type\": \"Prediction 0\"}, {\"pt\": 160.0, \"corr\": [1.0058326721191406], \"type\": \"Prediction 0\"}, {\"pt\": 165.0, \"corr\": [1.0056136846542358], \"type\": \"Prediction 0\"}, {\"pt\": 170.0, \"corr\": [1.005388617515564], \"type\": \"Prediction 0\"}, {\"pt\": 175.0, \"corr\": [1.0051543712615967], \"type\": \"Prediction 0\"}, {\"pt\": 180.0, \"corr\": [1.0049099922180176], \"type\": \"Prediction 0\"}, {\"pt\": 185.0, \"corr\": [1.004654884338379], \"type\": \"Prediction 0\"}, {\"pt\": 190.0, \"corr\": [1.0043902397155762], \"type\": \"Prediction 0\"}, {\"pt\": 195.0, \"corr\": [1.0041172504425049], \"type\": \"Prediction 0\"}, {\"pt\": 200.0, \"corr\": [1.0038363933563232], \"type\": \"Prediction 0\"}, {\"pt\": 205.0, \"corr\": [1.0035500526428223], \"type\": \"Prediction 0\"}, {\"pt\": 210.0, \"corr\": [1.0032598972320557], \"type\": \"Prediction 0\"}, {\"pt\": 215.0, \"corr\": [1.0029674768447876], \"type\": \"Prediction 0\"}, {\"pt\": 220.0, \"corr\": [1.002675175666809], \"type\": \"Prediction 0\"}, {\"pt\": 225.0, \"corr\": [1.002383828163147], \"type\": \"Prediction 0\"}, {\"pt\": 230.0, \"corr\": [1.0020959377288818], \"type\": \"Prediction 0\"}, {\"pt\": 235.0, \"corr\": [1.0018119812011719], \"type\": \"Prediction 0\"}, {\"pt\": 240.0, \"corr\": [1.001534104347229], \"type\": \"Prediction 0\"}, {\"pt\": 245.0, \"corr\": [1.0012633800506592], \"type\": \"Prediction 0\"}, {\"pt\": 250.0, \"corr\": [1.0010005235671997], \"type\": \"Prediction 0\"}, {\"pt\": 255.0, \"corr\": [1.000746726989746], \"type\": \"Prediction 0\"}, {\"pt\": 260.0, \"corr\": [1.0005024671554565], \"type\": \"Prediction 0\"}, {\"pt\": 265.0, \"corr\": [1.000268578529358], \"type\": \"Prediction 0\"}, {\"pt\": 270.0, \"corr\": [1.0000457763671875], \"type\": \"Prediction 0\"}, {\"pt\": 275.0, \"corr\": [0.999833881855011], \"type\": \"Prediction 0\"}, {\"pt\": 280.0, \"corr\": [0.9996335506439209], \"type\": \"Prediction 0\"}, {\"pt\": 285.0, \"corr\": [0.9994451999664307], \"type\": \"Prediction 0\"}, {\"pt\": 290.0, \"corr\": [0.9992684125900269], \"type\": \"Prediction 0\"}, {\"pt\": 295.0, \"corr\": [0.9991039633750916], \"type\": \"Prediction 0\"}, {\"pt\": 300.0, \"corr\": [0.9989510774612427], \"type\": \"Prediction 0\"}, {\"pt\": 305.0, \"corr\": [0.9988101720809937], \"type\": \"Prediction 0\"}, {\"pt\": 310.0, \"corr\": [0.9986810684204102], \"type\": \"Prediction 0\"}, {\"pt\": 315.0, \"corr\": [0.9985637068748474], \"type\": \"Prediction 0\"}, {\"pt\": 320.0, \"corr\": [0.9984577894210815], \"type\": \"Prediction 0\"}, {\"pt\": 325.0, \"corr\": [0.9983627200126648], \"type\": \"Prediction 0\"}, {\"pt\": 330.0, \"corr\": [0.9982787370681763], \"type\": \"Prediction 0\"}, {\"pt\": 335.0, \"corr\": [0.9982061386108398], \"type\": \"Prediction 0\"}, {\"pt\": 340.0, \"corr\": [0.9981433749198914], \"type\": \"Prediction 0\"}, {\"pt\": 345.0, \"corr\": [0.9980907440185547], \"type\": \"Prediction 0\"}, {\"pt\": 350.0, \"corr\": [0.9980484247207642], \"type\": \"Prediction 0\"}, {\"pt\": 355.0, \"corr\": [0.9980154633522034], \"type\": \"Prediction 0\"}, {\"pt\": 360.0, \"corr\": [0.997991681098938], \"type\": \"Prediction 0\"}, {\"pt\": 365.0, \"corr\": [0.9979770183563232], \"type\": \"Prediction 0\"}, {\"pt\": 370.0, \"corr\": [0.9979709386825562], \"type\": \"Prediction 0\"}, {\"pt\": 375.0, \"corr\": [0.9979729652404785], \"type\": \"Prediction 0\"}, {\"pt\": 380.0, \"corr\": [0.9979836940765381], \"type\": \"Prediction 0\"}, {\"pt\": 385.0, \"corr\": [0.9980015754699707], \"type\": \"Prediction 0\"}, {\"pt\": 390.0, \"corr\": [0.9980268478393555], \"type\": \"Prediction 0\"}, {\"pt\": 395.0, \"corr\": [0.9980592727661133], \"type\": \"Prediction 0\"}, {\"pt\": 400.0, \"corr\": [0.9980986714363098], \"type\": \"Prediction 0\"}, {\"pt\": 405.0, \"corr\": [0.9981443881988525], \"type\": \"Prediction 0\"}, {\"pt\": 410.0, \"corr\": [0.9981961250305176], \"type\": \"Prediction 0\"}, {\"pt\": 415.0, \"corr\": [0.998253345489502], \"type\": \"Prediction 0\"}, {\"pt\": 420.0, \"corr\": [0.9983161687850952], \"type\": \"Prediction 0\"}, {\"pt\": 425.0, \"corr\": [0.9983841180801392], \"type\": \"Prediction 0\"}, {\"pt\": 430.0, \"corr\": [0.9984564781188965], \"type\": \"Prediction 0\"}, {\"pt\": 435.0, \"corr\": [0.9985332489013672], \"type\": \"Prediction 0\"}, {\"pt\": 440.0, \"corr\": [0.9986140727996826], \"type\": \"Prediction 0\"}, {\"pt\": 445.0, \"corr\": [0.9986987113952637], \"type\": \"Prediction 0\"}, {\"pt\": 450.0, \"corr\": [0.9987863898277283], \"type\": \"Prediction 0\"}, {\"pt\": 455.0, \"corr\": [0.9988770484924316], \"type\": \"Prediction 0\"}, {\"pt\": 460.0, \"corr\": [0.9989701509475708], \"type\": \"Prediction 0\"}, {\"pt\": 465.0, \"corr\": [0.9990651607513428], \"type\": \"Prediction 0\"}, {\"pt\": 470.0, \"corr\": [0.9991618394851685], \"type\": \"Prediction 0\"}, {\"pt\": 475.0, \"corr\": [0.9992601275444031], \"type\": \"Prediction 0\"}, {\"pt\": 480.0, \"corr\": [0.999358594417572], \"type\": \"Prediction 0\"}, {\"pt\": 485.0, \"corr\": [0.9994586110115051], \"type\": \"Prediction 0\"}, {\"pt\": 490.0, \"corr\": [0.9995574951171875], \"type\": \"Prediction 0\"}, {\"pt\": 495.0, \"corr\": [0.9996567368507385], \"type\": \"Prediction 0\"}, {\"pt\": 10.0, \"corr\": [1.7618958950042725], \"type\": \"Prediction -pi/2\"}, {\"pt\": 15.0, \"corr\": [1.5247166156768799], \"type\": \"Prediction -pi/2\"}, {\"pt\": 20.0, \"corr\": [1.365303635597229], \"type\": \"Prediction -pi/2\"}, {\"pt\": 25.0, \"corr\": [1.2657077312469482], \"type\": \"Prediction -pi/2\"}, {\"pt\": 30.0, \"corr\": [1.2007322311401367], \"type\": \"Prediction -pi/2\"}, {\"pt\": 35.0, \"corr\": [1.155804991722107], \"type\": \"Prediction -pi/2\"}, {\"pt\": 40.0, \"corr\": [1.1231186389923096], \"type\": \"Prediction -pi/2\"}, {\"pt\": 45.0, \"corr\": [1.098330020904541], \"type\": \"Prediction -pi/2\"}, {\"pt\": 50.0, \"corr\": [1.0789402723312378], \"type\": \"Prediction -pi/2\"}, {\"pt\": 55.0, \"corr\": [1.0634657144546509], \"type\": \"Prediction -pi/2\"}, {\"pt\": 60.0, \"corr\": [1.050984263420105], \"type\": \"Prediction -pi/2\"}, {\"pt\": 65.0, \"corr\": [1.0408859252929688], \"type\": \"Prediction -pi/2\"}, {\"pt\": 70.0, \"corr\": [1.0327357053756714], \"type\": \"Prediction -pi/2\"}, {\"pt\": 75.0, \"corr\": [1.026201605796814], \"type\": \"Prediction -pi/2\"}, {\"pt\": 80.0, \"corr\": [1.0210158824920654], \"type\": \"Prediction -pi/2\"}, {\"pt\": 85.0, \"corr\": [1.0169545412063599], \"type\": \"Prediction -pi/2\"}, {\"pt\": 90.0, \"corr\": [1.0138251781463623], \"type\": \"Prediction -pi/2\"}, {\"pt\": 95.0, \"corr\": [1.011462688446045], \"type\": \"Prediction -pi/2\"}, {\"pt\": 100.0, \"corr\": [1.0097240209579468], \"type\": \"Prediction -pi/2\"}, {\"pt\": 105.0, \"corr\": [1.0084861516952515], \"type\": \"Prediction -pi/2\"}, {\"pt\": 110.0, \"corr\": [1.0076442956924438], \"type\": \"Prediction -pi/2\"}, {\"pt\": 115.0, \"corr\": [1.0071096420288086], \"type\": \"Prediction -pi/2\"}, {\"pt\": 120.0, \"corr\": [1.0068073272705078], \"type\": \"Prediction -pi/2\"}, {\"pt\": 125.0, \"corr\": [1.0066752433776855], \"type\": \"Prediction -pi/2\"}, {\"pt\": 130.0, \"corr\": [1.0066627264022827], \"type\": \"Prediction -pi/2\"}, {\"pt\": 135.0, \"corr\": [1.0067275762557983], \"type\": \"Prediction -pi/2\"}, {\"pt\": 140.0, \"corr\": [1.0068377256393433], \"type\": \"Prediction -pi/2\"}, {\"pt\": 145.0, \"corr\": [1.0069661140441895], \"type\": \"Prediction -pi/2\"}, {\"pt\": 150.0, \"corr\": [1.0070929527282715], \"type\": \"Prediction -pi/2\"}, {\"pt\": 155.0, \"corr\": [1.0072026252746582], \"type\": \"Prediction -pi/2\"}, {\"pt\": 160.0, \"corr\": [1.00728440284729], \"type\": \"Prediction -pi/2\"}, {\"pt\": 165.0, \"corr\": [1.0073304176330566], \"type\": \"Prediction -pi/2\"}, {\"pt\": 170.0, \"corr\": [1.007335901260376], \"type\": \"Prediction -pi/2\"}, {\"pt\": 175.0, \"corr\": [1.0072978734970093], \"type\": \"Prediction -pi/2\"}, {\"pt\": 180.0, \"corr\": [1.007216215133667], \"type\": \"Prediction -pi/2\"}, {\"pt\": 185.0, \"corr\": [1.0070909261703491], \"type\": \"Prediction -pi/2\"}, {\"pt\": 190.0, \"corr\": [1.0069239139556885], \"type\": \"Prediction -pi/2\"}, {\"pt\": 195.0, \"corr\": [1.0067174434661865], \"type\": \"Prediction -pi/2\"}, {\"pt\": 200.0, \"corr\": [1.0064749717712402], \"type\": \"Prediction -pi/2\"}, {\"pt\": 205.0, \"corr\": [1.006199598312378], \"type\": \"Prediction -pi/2\"}, {\"pt\": 210.0, \"corr\": [1.0058947801589966], \"type\": \"Prediction -pi/2\"}, {\"pt\": 215.0, \"corr\": [1.005564570426941], \"type\": \"Prediction -pi/2\"}, {\"pt\": 220.0, \"corr\": [1.005212664604187], \"type\": \"Prediction -pi/2\"}, {\"pt\": 225.0, \"corr\": [1.0048432350158691], \"type\": \"Prediction -pi/2\"}, {\"pt\": 230.0, \"corr\": [1.0044591426849365], \"type\": \"Prediction -pi/2\"}, {\"pt\": 235.0, \"corr\": [1.0040645599365234], \"type\": \"Prediction -pi/2\"}, {\"pt\": 240.0, \"corr\": [1.0036627054214478], \"type\": \"Prediction -pi/2\"}, {\"pt\": 245.0, \"corr\": [1.0032562017440796], \"type\": \"Prediction -pi/2\"}, {\"pt\": 250.0, \"corr\": [1.0028483867645264], \"type\": \"Prediction -pi/2\"}, {\"pt\": 255.0, \"corr\": [1.0024418830871582], \"type\": \"Prediction -pi/2\"}, {\"pt\": 260.0, \"corr\": [1.0020389556884766], \"type\": \"Prediction -pi/2\"}, {\"pt\": 265.0, \"corr\": [1.001641869544983], \"type\": \"Prediction -pi/2\"}, {\"pt\": 270.0, \"corr\": [1.0012527704238892], \"type\": \"Prediction -pi/2\"}, {\"pt\": 275.0, \"corr\": [1.0008735656738281], \"type\": \"Prediction -pi/2\"}, {\"pt\": 280.0, \"corr\": [1.0005052089691162], \"type\": \"Prediction -pi/2\"}, {\"pt\": 285.0, \"corr\": [1.0001498460769653], \"type\": \"Prediction -pi/2\"}, {\"pt\": 290.0, \"corr\": [0.9998087286949158], \"type\": \"Prediction -pi/2\"}, {\"pt\": 295.0, \"corr\": [0.9994823932647705], \"type\": \"Prediction -pi/2\"}, {\"pt\": 300.0, \"corr\": [0.9991723895072937], \"type\": \"Prediction -pi/2\"}, {\"pt\": 305.0, \"corr\": [0.9988789558410645], \"type\": \"Prediction -pi/2\"}, {\"pt\": 310.0, \"corr\": [0.9986032843589783], \"type\": \"Prediction -pi/2\"}, {\"pt\": 315.0, \"corr\": [0.9983454942703247], \"type\": \"Prediction -pi/2\"}, {\"pt\": 320.0, \"corr\": [0.9981058835983276], \"type\": \"Prediction -pi/2\"}, {\"pt\": 325.0, \"corr\": [0.9978852272033691], \"type\": \"Prediction -pi/2\"}, {\"pt\": 330.0, \"corr\": [0.9976834654808044], \"type\": \"Prediction -pi/2\"}, {\"pt\": 335.0, \"corr\": [0.9975006580352783], \"type\": \"Prediction -pi/2\"}, {\"pt\": 340.0, \"corr\": [0.9973375201225281], \"type\": \"Prediction -pi/2\"}, {\"pt\": 345.0, \"corr\": [0.9971929788589478], \"type\": \"Prediction -pi/2\"}, {\"pt\": 350.0, \"corr\": [0.9970681071281433], \"type\": \"Prediction -pi/2\"}, {\"pt\": 355.0, \"corr\": [0.9969618916511536], \"type\": \"Prediction -pi/2\"}, {\"pt\": 360.0, \"corr\": [0.9968743324279785], \"type\": \"Prediction -pi/2\"}, {\"pt\": 365.0, \"corr\": [0.9968054294586182], \"type\": \"Prediction -pi/2\"}, {\"pt\": 370.0, \"corr\": [0.9967549443244934], \"type\": \"Prediction -pi/2\"}, {\"pt\": 375.0, \"corr\": [0.9967218041419983], \"type\": \"Prediction -pi/2\"}, {\"pt\": 380.0, \"corr\": [0.996706485748291], \"type\": \"Prediction -pi/2\"}, {\"pt\": 385.0, \"corr\": [0.9967085123062134], \"type\": \"Prediction -pi/2\"}, {\"pt\": 390.0, \"corr\": [0.9967267513275146], \"type\": \"Prediction -pi/2\"}, {\"pt\": 395.0, \"corr\": [0.996761679649353], \"type\": \"Prediction -pi/2\"}, {\"pt\": 400.0, \"corr\": [0.9968124032020569], \"type\": \"Prediction -pi/2\"}, {\"pt\": 405.0, \"corr\": [0.9968783259391785], \"type\": \"Prediction -pi/2\"}, {\"pt\": 410.0, \"corr\": [0.9969586730003357], \"type\": \"Prediction -pi/2\"}, {\"pt\": 415.0, \"corr\": [0.9970538020133972], \"type\": \"Prediction -pi/2\"}, {\"pt\": 420.0, \"corr\": [0.9971625804901123], \"type\": \"Prediction -pi/2\"}, {\"pt\": 425.0, \"corr\": [0.9972841739654541], \"type\": \"Prediction -pi/2\"}, {\"pt\": 430.0, \"corr\": [0.9974186420440674], \"type\": \"Prediction -pi/2\"}, {\"pt\": 435.0, \"corr\": [0.9975650310516357], \"type\": \"Prediction -pi/2\"}, {\"pt\": 440.0, \"corr\": [0.9977230429649353], \"type\": \"Prediction -pi/2\"}, {\"pt\": 445.0, \"corr\": [0.9978916049003601], \"type\": \"Prediction -pi/2\"}, {\"pt\": 450.0, \"corr\": [0.9980708360671997], \"type\": \"Prediction -pi/2\"}, {\"pt\": 455.0, \"corr\": [0.9982594847679138], \"type\": \"Prediction -pi/2\"}, {\"pt\": 460.0, \"corr\": [0.9984571933746338], \"type\": \"Prediction -pi/2\"}, {\"pt\": 465.0, \"corr\": [0.9986635446548462], \"type\": \"Prediction -pi/2\"}, {\"pt\": 470.0, \"corr\": [0.9988774061203003], \"type\": \"Prediction -pi/2\"}, {\"pt\": 475.0, \"corr\": [0.9990993738174438], \"type\": \"Prediction -pi/2\"}, {\"pt\": 480.0, \"corr\": [0.9993271231651306], \"type\": \"Prediction -pi/2\"}, {\"pt\": 485.0, \"corr\": [0.9995613694190979], \"type\": \"Prediction -pi/2\"}, {\"pt\": 490.0, \"corr\": [0.999800980091095], \"type\": \"Prediction -pi/2\"}, {\"pt\": 495.0, \"corr\": [1.0000457763671875], \"type\": \"Prediction -pi/2\"}, {\"pt\": 10.0, \"corr\": [1.7617368698120117], \"type\": \"Prediction  pi/2\"}, {\"pt\": 15.0, \"corr\": [1.5248782634735107], \"type\": \"Prediction  pi/2\"}, {\"pt\": 20.0, \"corr\": [1.369207501411438], \"type\": \"Prediction  pi/2\"}, {\"pt\": 25.0, \"corr\": [1.2715973854064941], \"type\": \"Prediction  pi/2\"}, {\"pt\": 30.0, \"corr\": [1.2068476676940918], \"type\": \"Prediction  pi/2\"}, {\"pt\": 35.0, \"corr\": [1.1613011360168457], \"type\": \"Prediction  pi/2\"}, {\"pt\": 40.0, \"corr\": [1.1277761459350586], \"type\": \"Prediction  pi/2\"}, {\"pt\": 45.0, \"corr\": [1.102243185043335], \"type\": \"Prediction  pi/2\"}, {\"pt\": 50.0, \"corr\": [1.0823185443878174], \"type\": \"Prediction  pi/2\"}, {\"pt\": 55.0, \"corr\": [1.0665215253829956], \"type\": \"Prediction  pi/2\"}, {\"pt\": 60.0, \"corr\": [1.0538830757141113], \"type\": \"Prediction  pi/2\"}, {\"pt\": 65.0, \"corr\": [1.0437321662902832], \"type\": \"Prediction  pi/2\"}, {\"pt\": 70.0, \"corr\": [1.0355807542800903], \"type\": \"Prediction  pi/2\"}, {\"pt\": 75.0, \"corr\": [1.029057502746582], \"type\": \"Prediction  pi/2\"}, {\"pt\": 80.0, \"corr\": [1.023868203163147], \"type\": \"Prediction  pi/2\"}, {\"pt\": 85.0, \"corr\": [1.0197734832763672], \"type\": \"Prediction  pi/2\"}, {\"pt\": 90.0, \"corr\": [1.016573429107666], \"type\": \"Prediction  pi/2\"}, {\"pt\": 95.0, \"corr\": [1.0140998363494873], \"type\": \"Prediction  pi/2\"}, {\"pt\": 100.0, \"corr\": [1.0122102499008179], \"type\": \"Prediction  pi/2\"}, {\"pt\": 105.0, \"corr\": [1.0107836723327637], \"type\": \"Prediction  pi/2\"}, {\"pt\": 110.0, \"corr\": [1.0097181797027588], \"type\": \"Prediction  pi/2\"}, {\"pt\": 115.0, \"corr\": [1.0089287757873535], \"type\": \"Prediction  pi/2\"}, {\"pt\": 120.0, \"corr\": [1.0083460807800293], \"type\": \"Prediction  pi/2\"}, {\"pt\": 125.0, \"corr\": [1.0079126358032227], \"type\": \"Prediction  pi/2\"}, {\"pt\": 130.0, \"corr\": [1.0075829029083252], \"type\": \"Prediction  pi/2\"}, {\"pt\": 135.0, \"corr\": [1.0073208808898926], \"type\": \"Prediction  pi/2\"}, {\"pt\": 140.0, \"corr\": [1.00709867477417], \"type\": \"Prediction  pi/2\"}, {\"pt\": 145.0, \"corr\": [1.0068953037261963], \"type\": \"Prediction  pi/2\"}, {\"pt\": 150.0, \"corr\": [1.0066959857940674], \"type\": \"Prediction  pi/2\"}, {\"pt\": 155.0, \"corr\": [1.0064895153045654], \"type\": \"Prediction  pi/2\"}, {\"pt\": 160.0, \"corr\": [1.0062694549560547], \"type\": \"Prediction  pi/2\"}, {\"pt\": 165.0, \"corr\": [1.006030797958374], \"type\": \"Prediction  pi/2\"}, {\"pt\": 170.0, \"corr\": [1.005772590637207], \"type\": \"Prediction  pi/2\"}, {\"pt\": 175.0, \"corr\": [1.0054938793182373], \"type\": \"Prediction  pi/2\"}, {\"pt\": 180.0, \"corr\": [1.0051958560943604], \"type\": \"Prediction  pi/2\"}, {\"pt\": 185.0, \"corr\": [1.0048803091049194], \"type\": \"Prediction  pi/2\"}, {\"pt\": 190.0, \"corr\": [1.0045499801635742], \"type\": \"Prediction  pi/2\"}, {\"pt\": 195.0, \"corr\": [1.0042074918746948], \"type\": \"Prediction  pi/2\"}, {\"pt\": 200.0, \"corr\": [1.0038553476333618], \"type\": \"Prediction  pi/2\"}, {\"pt\": 205.0, \"corr\": [1.0034968852996826], \"type\": \"Prediction  pi/2\"}, {\"pt\": 210.0, \"corr\": [1.0031347274780273], \"type\": \"Prediction  pi/2\"}, {\"pt\": 215.0, \"corr\": [1.0027717351913452], \"type\": \"Prediction  pi/2\"}, {\"pt\": 220.0, \"corr\": [1.0024101734161377], \"type\": \"Prediction  pi/2\"}, {\"pt\": 225.0, \"corr\": [1.0020525455474854], \"type\": \"Prediction  pi/2\"}, {\"pt\": 230.0, \"corr\": [1.001700758934021], \"type\": \"Prediction  pi/2\"}, {\"pt\": 235.0, \"corr\": [1.001356601715088], \"type\": \"Prediction  pi/2\"}, {\"pt\": 240.0, \"corr\": [1.0010217428207397], \"type\": \"Prediction  pi/2\"}, {\"pt\": 245.0, \"corr\": [1.0006978511810303], \"type\": \"Prediction  pi/2\"}, {\"pt\": 250.0, \"corr\": [1.0003855228424072], \"type\": \"Prediction  pi/2\"}, {\"pt\": 255.0, \"corr\": [1.0000860691070557], \"type\": \"Prediction  pi/2\"}, {\"pt\": 260.0, \"corr\": [0.9998003840446472], \"type\": \"Prediction  pi/2\"}, {\"pt\": 265.0, \"corr\": [0.999528706073761], \"type\": \"Prediction  pi/2\"}, {\"pt\": 270.0, \"corr\": [0.9992713332176208], \"type\": \"Prediction  pi/2\"}, {\"pt\": 275.0, \"corr\": [0.9990293979644775], \"type\": \"Prediction  pi/2\"}, {\"pt\": 280.0, \"corr\": [0.9988023042678833], \"type\": \"Prediction  pi/2\"}, {\"pt\": 285.0, \"corr\": [0.9985899925231934], \"type\": \"Prediction  pi/2\"}, {\"pt\": 290.0, \"corr\": [0.9983934164047241], \"type\": \"Prediction  pi/2\"}, {\"pt\": 295.0, \"corr\": [0.998211145401001], \"type\": \"Prediction  pi/2\"}, {\"pt\": 300.0, \"corr\": [0.998044490814209], \"type\": \"Prediction  pi/2\"}, {\"pt\": 305.0, \"corr\": [0.9978916645050049], \"type\": \"Prediction  pi/2\"}, {\"pt\": 310.0, \"corr\": [0.997753381729126], \"type\": \"Prediction  pi/2\"}, {\"pt\": 315.0, \"corr\": [0.9976285696029663], \"type\": \"Prediction  pi/2\"}, {\"pt\": 320.0, \"corr\": [0.997517466545105], \"type\": \"Prediction  pi/2\"}, {\"pt\": 325.0, \"corr\": [0.9974191188812256], \"type\": \"Prediction  pi/2\"}, {\"pt\": 330.0, \"corr\": [0.9973329305648804], \"type\": \"Prediction  pi/2\"}, {\"pt\": 335.0, \"corr\": [0.9972587823867798], \"type\": \"Prediction  pi/2\"}, {\"pt\": 340.0, \"corr\": [0.997195839881897], \"type\": \"Prediction  pi/2\"}, {\"pt\": 345.0, \"corr\": [0.9971434473991394], \"type\": \"Prediction  pi/2\"}, {\"pt\": 350.0, \"corr\": [0.9971011281013489], \"type\": \"Prediction  pi/2\"}, {\"pt\": 355.0, \"corr\": [0.9970682859420776], \"type\": \"Prediction  pi/2\"}, {\"pt\": 360.0, \"corr\": [0.9970440864562988], \"type\": \"Prediction  pi/2\"}, {\"pt\": 365.0, \"corr\": [0.9970278739929199], \"type\": \"Prediction  pi/2\"}, {\"pt\": 370.0, \"corr\": [0.9970192909240723], \"type\": \"Prediction  pi/2\"}, {\"pt\": 375.0, \"corr\": [0.9970172643661499], \"type\": \"Prediction  pi/2\"}, {\"pt\": 380.0, \"corr\": [0.9970210194587708], \"type\": \"Prediction  pi/2\"}, {\"pt\": 385.0, \"corr\": [0.9970303773880005], \"type\": \"Prediction  pi/2\"}, {\"pt\": 390.0, \"corr\": [0.9970436096191406], \"type\": \"Prediction  pi/2\"}, {\"pt\": 395.0, \"corr\": [0.9970605969429016], \"type\": \"Prediction  pi/2\"}, {\"pt\": 400.0, \"corr\": [0.9970806837081909], \"type\": \"Prediction  pi/2\"}, {\"pt\": 405.0, \"corr\": [0.9971029162406921], \"type\": \"Prediction  pi/2\"}, {\"pt\": 410.0, \"corr\": [0.9971267580986023], \"type\": \"Prediction  pi/2\"}, {\"pt\": 415.0, \"corr\": [0.9971508383750916], \"type\": \"Prediction  pi/2\"}, {\"pt\": 420.0, \"corr\": [0.9971750974655151], \"type\": \"Prediction  pi/2\"}, {\"pt\": 425.0, \"corr\": [0.9971983432769775], \"type\": \"Prediction  pi/2\"}, {\"pt\": 430.0, \"corr\": [0.9972198605537415], \"type\": \"Prediction  pi/2\"}, {\"pt\": 435.0, \"corr\": [0.9972392320632935], \"type\": \"Prediction  pi/2\"}, {\"pt\": 440.0, \"corr\": [0.9972552061080933], \"type\": \"Prediction  pi/2\"}, {\"pt\": 445.0, \"corr\": [0.9972667694091797], \"type\": \"Prediction  pi/2\"}, {\"pt\": 450.0, \"corr\": [0.997273862361908], \"type\": \"Prediction  pi/2\"}, {\"pt\": 455.0, \"corr\": [0.9972752332687378], \"type\": \"Prediction  pi/2\"}, {\"pt\": 460.0, \"corr\": [0.9972702860832214], \"type\": \"Prediction  pi/2\"}, {\"pt\": 465.0, \"corr\": [0.9972584843635559], \"type\": \"Prediction  pi/2\"}, {\"pt\": 470.0, \"corr\": [0.9972385168075562], \"type\": \"Prediction  pi/2\"}, {\"pt\": 475.0, \"corr\": [0.9972100257873535], \"type\": \"Prediction  pi/2\"}, {\"pt\": 480.0, \"corr\": [0.9971722364425659], \"type\": \"Prediction  pi/2\"}, {\"pt\": 485.0, \"corr\": [0.9971244931221008], \"type\": \"Prediction  pi/2\"}, {\"pt\": 490.0, \"corr\": [0.9970654249191284], \"type\": \"Prediction  pi/2\"}, {\"pt\": 495.0, \"corr\": [0.9969954490661621], \"type\": \"Prediction  pi/2\"}, {\"pt\": 10.0, \"corr\": [1.7543153762817383], \"type\": \"Prediction -pi\"}, {\"pt\": 15.0, \"corr\": [1.5201761722564697], \"type\": \"Prediction -pi\"}, {\"pt\": 20.0, \"corr\": [1.3656601905822754], \"type\": \"Prediction -pi\"}, {\"pt\": 25.0, \"corr\": [1.2687989473342896], \"type\": \"Prediction -pi\"}, {\"pt\": 30.0, \"corr\": [1.2047638893127441], \"type\": \"Prediction -pi\"}, {\"pt\": 35.0, \"corr\": [1.1598892211914062], \"type\": \"Prediction -pi\"}, {\"pt\": 40.0, \"corr\": [1.1269562244415283], \"type\": \"Prediction -pi\"}, {\"pt\": 45.0, \"corr\": [1.1019232273101807], \"type\": \"Prediction -pi\"}, {\"pt\": 50.0, \"corr\": [1.082409143447876], \"type\": \"Prediction -pi\"}, {\"pt\": 55.0, \"corr\": [1.0669434070587158], \"type\": \"Prediction -pi\"}, {\"pt\": 60.0, \"corr\": [1.0545682907104492], \"type\": \"Prediction -pi\"}, {\"pt\": 65.0, \"corr\": [1.0446233749389648], \"type\": \"Prediction -pi\"}, {\"pt\": 70.0, \"corr\": [1.0366277694702148], \"type\": \"Prediction -pi\"}, {\"pt\": 75.0, \"corr\": [1.0302143096923828], \"type\": \"Prediction -pi\"}, {\"pt\": 80.0, \"corr\": [1.0250921249389648], \"type\": \"Prediction -pi\"}, {\"pt\": 85.0, \"corr\": [1.0210247039794922], \"type\": \"Prediction -pi\"}, {\"pt\": 90.0, \"corr\": [1.0178158283233643], \"type\": \"Prediction -pi\"}, {\"pt\": 95.0, \"corr\": [1.015302300453186], \"type\": \"Prediction -pi\"}, {\"pt\": 100.0, \"corr\": [1.0133464336395264], \"type\": \"Prediction -pi\"}, {\"pt\": 105.0, \"corr\": [1.0118335485458374], \"type\": \"Prediction -pi\"}, {\"pt\": 110.0, \"corr\": [1.0106678009033203], \"type\": \"Prediction -pi\"}, {\"pt\": 115.0, \"corr\": [1.0097712278366089], \"type\": \"Prediction -pi\"}, {\"pt\": 120.0, \"corr\": [1.0090782642364502], \"type\": \"Prediction -pi\"}, {\"pt\": 125.0, \"corr\": [1.0085375308990479], \"type\": \"Prediction -pi\"}, {\"pt\": 130.0, \"corr\": [1.0081069469451904], \"type\": \"Prediction -pi\"}, {\"pt\": 135.0, \"corr\": [1.007753610610962], \"type\": \"Prediction -pi\"}, {\"pt\": 140.0, \"corr\": [1.007452130317688], \"type\": \"Prediction -pi\"}, {\"pt\": 145.0, \"corr\": [1.007183313369751], \"type\": \"Prediction -pi\"}, {\"pt\": 150.0, \"corr\": [1.006932258605957], \"type\": \"Prediction -pi\"}, {\"pt\": 155.0, \"corr\": [1.0066883563995361], \"type\": \"Prediction -pi\"}, {\"pt\": 160.0, \"corr\": [1.0064451694488525], \"type\": \"Prediction -pi\"}, {\"pt\": 165.0, \"corr\": [1.0061967372894287], \"type\": \"Prediction -pi\"}, {\"pt\": 170.0, \"corr\": [1.0059406757354736], \"type\": \"Prediction -pi\"}, {\"pt\": 175.0, \"corr\": [1.0056757926940918], \"type\": \"Prediction -pi\"}, {\"pt\": 180.0, \"corr\": [1.005401372909546], \"type\": \"Prediction -pi\"}, {\"pt\": 185.0, \"corr\": [1.0051183700561523], \"type\": \"Prediction -pi\"}, {\"pt\": 190.0, \"corr\": [1.0048272609710693], \"type\": \"Prediction -pi\"}, {\"pt\": 195.0, \"corr\": [1.0045300722122192], \"type\": \"Prediction -pi\"}, {\"pt\": 200.0, \"corr\": [1.004227876663208], \"type\": \"Prediction -pi\"}, {\"pt\": 205.0, \"corr\": [1.0039228200912476], \"type\": \"Prediction -pi\"}, {\"pt\": 210.0, \"corr\": [1.0036160945892334], \"type\": \"Prediction -pi\"}, {\"pt\": 215.0, \"corr\": [1.0033098459243774], \"type\": \"Prediction -pi\"}, {\"pt\": 220.0, \"corr\": [1.003005862236023], \"type\": \"Prediction -pi\"}, {\"pt\": 225.0, \"corr\": [1.0027053356170654], \"type\": \"Prediction -pi\"}, {\"pt\": 230.0, \"corr\": [1.0024092197418213], \"type\": \"Prediction -pi\"}, {\"pt\": 235.0, \"corr\": [1.002119541168213], \"type\": \"Prediction -pi\"}, {\"pt\": 240.0, \"corr\": [1.001836895942688], \"type\": \"Prediction -pi\"}, {\"pt\": 245.0, \"corr\": [1.001562237739563], \"type\": \"Prediction -pi\"}, {\"pt\": 250.0, \"corr\": [1.0012967586517334], \"type\": \"Prediction -pi\"}, {\"pt\": 255.0, \"corr\": [1.0010404586791992], \"type\": \"Prediction -pi\"}, {\"pt\": 260.0, \"corr\": [1.000794529914856], \"type\": \"Prediction -pi\"}, {\"pt\": 265.0, \"corr\": [1.000558853149414], \"type\": \"Prediction -pi\"}, {\"pt\": 270.0, \"corr\": [1.0003345012664795], \"type\": \"Prediction -pi\"}, {\"pt\": 275.0, \"corr\": [1.0001206398010254], \"type\": \"Prediction -pi\"}, {\"pt\": 280.0, \"corr\": [0.9999184608459473], \"type\": \"Prediction -pi\"}, {\"pt\": 285.0, \"corr\": [0.9997279644012451], \"type\": \"Prediction -pi\"}, {\"pt\": 290.0, \"corr\": [0.9995485544204712], \"type\": \"Prediction -pi\"}, {\"pt\": 295.0, \"corr\": [0.9993804693222046], \"type\": \"Prediction -pi\"}, {\"pt\": 300.0, \"corr\": [0.999224066734314], \"type\": \"Prediction -pi\"}, {\"pt\": 305.0, \"corr\": [0.9990785121917725], \"type\": \"Prediction -pi\"}, {\"pt\": 310.0, \"corr\": [0.9989444613456726], \"type\": \"Prediction -pi\"}, {\"pt\": 315.0, \"corr\": [0.9988209009170532], \"type\": \"Prediction -pi\"}, {\"pt\": 320.0, \"corr\": [0.9987084865570068], \"type\": \"Prediction -pi\"}, {\"pt\": 325.0, \"corr\": [0.9986060857772827], \"type\": \"Prediction -pi\"}, {\"pt\": 330.0, \"corr\": [0.9985144138336182], \"type\": \"Prediction -pi\"}, {\"pt\": 335.0, \"corr\": [0.9984321594238281], \"type\": \"Prediction -pi\"}, {\"pt\": 340.0, \"corr\": [0.998359739780426], \"type\": \"Prediction -pi\"}, {\"pt\": 345.0, \"corr\": [0.9982966184616089], \"type\": \"Prediction -pi\"}, {\"pt\": 350.0, \"corr\": [0.9982428550720215], \"type\": \"Prediction -pi\"}, {\"pt\": 355.0, \"corr\": [0.9981973171234131], \"type\": \"Prediction -pi\"}, {\"pt\": 360.0, \"corr\": [0.9981601238250732], \"type\": \"Prediction -pi\"}, {\"pt\": 365.0, \"corr\": [0.9981309175491333], \"type\": \"Prediction -pi\"}, {\"pt\": 370.0, \"corr\": [0.9981093406677246], \"type\": \"Prediction -pi\"}, {\"pt\": 375.0, \"corr\": [0.998094916343689], \"type\": \"Prediction -pi\"}, {\"pt\": 380.0, \"corr\": [0.9980872869491577], \"type\": \"Prediction -pi\"}, {\"pt\": 385.0, \"corr\": [0.9980862140655518], \"type\": \"Prediction -pi\"}, {\"pt\": 390.0, \"corr\": [0.9980913400650024], \"type\": \"Prediction -pi\"}, {\"pt\": 395.0, \"corr\": [0.9981012940406799], \"type\": \"Prediction -pi\"}, {\"pt\": 400.0, \"corr\": [0.9981170892715454], \"type\": \"Prediction -pi\"}, {\"pt\": 405.0, \"corr\": [0.9981370568275452], \"type\": \"Prediction -pi\"}, {\"pt\": 410.0, \"corr\": [0.9981614947319031], \"type\": \"Prediction -pi\"}, {\"pt\": 415.0, \"corr\": [0.9981896877288818], \"type\": \"Prediction -pi\"}, {\"pt\": 420.0, \"corr\": [0.9982210993766785], \"type\": \"Prediction -pi\"}, {\"pt\": 425.0, \"corr\": [0.9982552528381348], \"type\": \"Prediction -pi\"}, {\"pt\": 430.0, \"corr\": [0.9982918500900269], \"type\": \"Prediction -pi\"}, {\"pt\": 435.0, \"corr\": [0.998330295085907], \"type\": \"Prediction -pi\"}, {\"pt\": 440.0, \"corr\": [0.998369574546814], \"type\": \"Prediction -pi\"}, {\"pt\": 445.0, \"corr\": [0.9984096884727478], \"type\": \"Prediction -pi\"}, {\"pt\": 450.0, \"corr\": [0.9984502792358398], \"type\": \"Prediction -pi\"}, {\"pt\": 455.0, \"corr\": [0.9984904527664185], \"type\": \"Prediction -pi\"}, {\"pt\": 460.0, \"corr\": [0.9985294342041016], \"type\": \"Prediction -pi\"}, {\"pt\": 465.0, \"corr\": [0.9985673427581787], \"type\": \"Prediction -pi\"}, {\"pt\": 470.0, \"corr\": [0.9986026287078857], \"type\": \"Prediction -pi\"}, {\"pt\": 475.0, \"corr\": [0.9986355900764465], \"type\": \"Prediction -pi\"}, {\"pt\": 480.0, \"corr\": [0.9986653327941895], \"type\": \"Prediction -pi\"}, {\"pt\": 485.0, \"corr\": [0.9986910820007324], \"type\": \"Prediction -pi\"}, {\"pt\": 490.0, \"corr\": [0.9987123012542725], \"type\": \"Prediction -pi\"}, {\"pt\": 495.0, \"corr\": [0.9987288117408752], \"type\": \"Prediction -pi\"}, {\"pt\": 10.0, \"corr\": [1.795651912689209], \"type\": \"Prediction  pi\"}, {\"pt\": 15.0, \"corr\": [1.5495408773422241], \"type\": \"Prediction  pi\"}, {\"pt\": 20.0, \"corr\": [1.3848865032196045], \"type\": \"Prediction  pi\"}, {\"pt\": 25.0, \"corr\": [1.2819998264312744], \"type\": \"Prediction  pi\"}, {\"pt\": 30.0, \"corr\": [1.2141692638397217], \"type\": \"Prediction  pi\"}, {\"pt\": 35.0, \"corr\": [1.1667181253433228], \"type\": \"Prediction  pi\"}, {\"pt\": 40.0, \"corr\": [1.1319434642791748], \"type\": \"Prediction  pi\"}, {\"pt\": 45.0, \"corr\": [1.1054961681365967], \"type\": \"Prediction  pi\"}, {\"pt\": 50.0, \"corr\": [1.084791898727417], \"type\": \"Prediction  pi\"}, {\"pt\": 55.0, \"corr\": [1.0682398080825806], \"type\": \"Prediction  pi\"}, {\"pt\": 60.0, \"corr\": [1.0548254251480103], \"type\": \"Prediction  pi\"}, {\"pt\": 65.0, \"corr\": [1.0438742637634277], \"type\": \"Prediction  pi\"}, {\"pt\": 70.0, \"corr\": [1.0349165201187134], \"type\": \"Prediction  pi\"}, {\"pt\": 75.0, \"corr\": [1.02760910987854], \"type\": \"Prediction  pi\"}, {\"pt\": 80.0, \"corr\": [1.0216882228851318], \"type\": \"Prediction  pi\"}, {\"pt\": 85.0, \"corr\": [1.0169408321380615], \"type\": \"Prediction  pi\"}, {\"pt\": 90.0, \"corr\": [1.013187050819397], \"type\": \"Prediction  pi\"}, {\"pt\": 95.0, \"corr\": [1.0102711915969849], \"type\": \"Prediction  pi\"}, {\"pt\": 100.0, \"corr\": [1.0080552101135254], \"type\": \"Prediction  pi\"}, {\"pt\": 105.0, \"corr\": [1.0064172744750977], \"type\": \"Prediction  pi\"}, {\"pt\": 110.0, \"corr\": [1.0052489042282104], \"type\": \"Prediction  pi\"}, {\"pt\": 115.0, \"corr\": [1.004455804824829], \"type\": \"Prediction  pi\"}, {\"pt\": 120.0, \"corr\": [1.0039548873901367], \"type\": \"Prediction  pi\"}, {\"pt\": 125.0, \"corr\": [1.0036756992340088], \"type\": \"Prediction  pi\"}, {\"pt\": 130.0, \"corr\": [1.0035591125488281], \"type\": \"Prediction  pi\"}, {\"pt\": 135.0, \"corr\": [1.0035549402236938], \"type\": \"Prediction  pi\"}, {\"pt\": 140.0, \"corr\": [1.0036227703094482], \"type\": \"Prediction  pi\"}, {\"pt\": 145.0, \"corr\": [1.0037310123443604], \"type\": \"Prediction  pi\"}, {\"pt\": 150.0, \"corr\": [1.003853440284729], \"type\": \"Prediction  pi\"}, {\"pt\": 155.0, \"corr\": [1.0039714574813843], \"type\": \"Prediction  pi\"}, {\"pt\": 160.0, \"corr\": [1.004070520401001], \"type\": \"Prediction  pi\"}, {\"pt\": 165.0, \"corr\": [1.0041414499282837], \"type\": \"Prediction  pi\"}, {\"pt\": 170.0, \"corr\": [1.0041778087615967], \"type\": \"Prediction  pi\"}, {\"pt\": 175.0, \"corr\": [1.0041759014129639], \"type\": \"Prediction  pi\"}, {\"pt\": 180.0, \"corr\": [1.0041344165802002], \"type\": \"Prediction  pi\"}, {\"pt\": 185.0, \"corr\": [1.0040545463562012], \"type\": \"Prediction  pi\"}, {\"pt\": 190.0, \"corr\": [1.0039376020431519], \"type\": \"Prediction  pi\"}, {\"pt\": 195.0, \"corr\": [1.003786325454712], \"type\": \"Prediction  pi\"}, {\"pt\": 200.0, \"corr\": [1.0036041736602783], \"type\": \"Prediction  pi\"}, {\"pt\": 205.0, \"corr\": [1.0033951997756958], \"type\": \"Prediction  pi\"}, {\"pt\": 210.0, \"corr\": [1.0031622648239136], \"type\": \"Prediction  pi\"}, {\"pt\": 215.0, \"corr\": [1.0029106140136719], \"type\": \"Prediction  pi\"}, {\"pt\": 220.0, \"corr\": [1.0026435852050781], \"type\": \"Prediction  pi\"}, {\"pt\": 225.0, \"corr\": [1.0023647546768188], \"type\": \"Prediction  pi\"}, {\"pt\": 230.0, \"corr\": [1.0020781755447388], \"type\": \"Prediction  pi\"}, {\"pt\": 235.0, \"corr\": [1.001786708831787], \"type\": \"Prediction  pi\"}, {\"pt\": 240.0, \"corr\": [1.0014927387237549], \"type\": \"Prediction  pi\"}, {\"pt\": 245.0, \"corr\": [1.001200556755066], \"type\": \"Prediction  pi\"}, {\"pt\": 250.0, \"corr\": [1.000910997390747], \"type\": \"Prediction  pi\"}, {\"pt\": 255.0, \"corr\": [1.0006266832351685], \"type\": \"Prediction  pi\"}, {\"pt\": 260.0, \"corr\": [1.0003498792648315], \"type\": \"Prediction  pi\"}, {\"pt\": 265.0, \"corr\": [1.0000810623168945], \"type\": \"Prediction  pi\"}, {\"pt\": 270.0, \"corr\": [0.9998221397399902], \"type\": \"Prediction  pi\"}, {\"pt\": 275.0, \"corr\": [0.9995741844177246], \"type\": \"Prediction  pi\"}, {\"pt\": 280.0, \"corr\": [0.9993374943733215], \"type\": \"Prediction  pi\"}, {\"pt\": 285.0, \"corr\": [0.9991132020950317], \"type\": \"Prediction  pi\"}, {\"pt\": 290.0, \"corr\": [0.9989016056060791], \"type\": \"Prediction  pi\"}, {\"pt\": 295.0, \"corr\": [0.9987022280693054], \"type\": \"Prediction  pi\"}, {\"pt\": 300.0, \"corr\": [0.9985156655311584], \"type\": \"Prediction  pi\"}, {\"pt\": 305.0, \"corr\": [0.9983417987823486], \"type\": \"Prediction  pi\"}, {\"pt\": 310.0, \"corr\": [0.9981802701950073], \"type\": \"Prediction  pi\"}, {\"pt\": 315.0, \"corr\": [0.9980305433273315], \"type\": \"Prediction  pi\"}, {\"pt\": 320.0, \"corr\": [0.9978926181793213], \"type\": \"Prediction  pi\"}, {\"pt\": 325.0, \"corr\": [0.9977655410766602], \"type\": \"Prediction  pi\"}, {\"pt\": 330.0, \"corr\": [0.9976489543914795], \"type\": \"Prediction  pi\"}, {\"pt\": 335.0, \"corr\": [0.997542142868042], \"type\": \"Prediction  pi\"}, {\"pt\": 340.0, \"corr\": [0.9974443316459656], \"type\": \"Prediction  pi\"}, {\"pt\": 345.0, \"corr\": [0.9973549842834473], \"type\": \"Prediction  pi\"}, {\"pt\": 350.0, \"corr\": [0.9972727298736572], \"type\": \"Prediction  pi\"}, {\"pt\": 355.0, \"corr\": [0.9971970915794373], \"type\": \"Prediction  pi\"}, {\"pt\": 360.0, \"corr\": [0.9971269369125366], \"type\": \"Prediction  pi\"}, {\"pt\": 365.0, \"corr\": [0.9970617890357971], \"type\": \"Prediction  pi\"}, {\"pt\": 370.0, \"corr\": [0.9970003366470337], \"type\": \"Prediction  pi\"}, {\"pt\": 375.0, \"corr\": [0.9969414472579956], \"type\": \"Prediction  pi\"}, {\"pt\": 380.0, \"corr\": [0.9968847036361694], \"type\": \"Prediction  pi\"}, {\"pt\": 385.0, \"corr\": [0.9968286156654358], \"type\": \"Prediction  pi\"}, {\"pt\": 390.0, \"corr\": [0.9967726469039917], \"type\": \"Prediction  pi\"}, {\"pt\": 395.0, \"corr\": [0.9967155456542969], \"type\": \"Prediction  pi\"}, {\"pt\": 400.0, \"corr\": [0.9966561794281006], \"type\": \"Prediction  pi\"}, {\"pt\": 405.0, \"corr\": [0.9965938329696655], \"type\": \"Prediction  pi\"}, {\"pt\": 410.0, \"corr\": [0.9965275526046753], \"type\": \"Prediction  pi\"}, {\"pt\": 415.0, \"corr\": [0.9964566826820374], \"type\": \"Prediction  pi\"}, {\"pt\": 420.0, \"corr\": [0.9963796138763428], \"type\": \"Prediction  pi\"}, {\"pt\": 425.0, \"corr\": [0.9962954521179199], \"type\": \"Prediction  pi\"}, {\"pt\": 430.0, \"corr\": [0.9962037801742554], \"type\": \"Prediction  pi\"}, {\"pt\": 435.0, \"corr\": [0.9961037039756775], \"type\": \"Prediction  pi\"}, {\"pt\": 440.0, \"corr\": [0.9959942102432251], \"type\": \"Prediction  pi\"}, {\"pt\": 445.0, \"corr\": [0.9958739876747131], \"type\": \"Prediction  pi\"}, {\"pt\": 450.0, \"corr\": [0.9957425594329834], \"type\": \"Prediction  pi\"}, {\"pt\": 455.0, \"corr\": [0.9955993890762329], \"type\": \"Prediction  pi\"}, {\"pt\": 460.0, \"corr\": [0.9954434037208557], \"type\": \"Prediction  pi\"}, {\"pt\": 465.0, \"corr\": [0.995273768901825], \"type\": \"Prediction  pi\"}, {\"pt\": 470.0, \"corr\": [0.9950898885726929], \"type\": \"Prediction  pi\"}, {\"pt\": 475.0, \"corr\": [0.9948911666870117], \"type\": \"Prediction  pi\"}, {\"pt\": 480.0, \"corr\": [0.9946767091751099], \"type\": \"Prediction  pi\"}, {\"pt\": 485.0, \"corr\": [0.9944459199905396], \"type\": \"Prediction  pi\"}, {\"pt\": 490.0, \"corr\": [0.9941980838775635], \"type\": \"Prediction  pi\"}, {\"pt\": 495.0, \"corr\": [0.9939326047897339], \"type\": \"Prediction  pi\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhhGGjH65De8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ae209e3-88d8-4830-e5b5-4e56c183766e"
      },
      "source": [
        "coeffrecurse(50,4)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.718774616794509"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwX8Fqv_2g_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}